# Theramind ğŸ§ ğŸ’¬

<div align="center">

**Your Personal AI Companion for Mental Wellness**

*Privacy-focused, on-device AI that runs entirely on your phone*

[![React Native](https://img.shields.io/badge/React%20Native-0.81.5-61DAFB?logo=react&logoColor=white)](https://reactnative.dev/)
[![Expo](https://img.shields.io/badge/Expo-~54.0.0-000020?logo=expo&logoColor=white)](https://expo.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.3.3-3178C6?logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Llama.cpp](https://img.shields.io/badge/llama.cpp-Local%20AI-00ADD8?logo=meta&logoColor=white)](https://github.com/ggerganov/llama.cpp)
[![Zustand](https://img.shields.io/badge/Zustand-State%20Management-FF6B6B)](https://github.com/pmndrs/zustand)
[![Reanimated](https://img.shields.io/badge/Reanimated-4.1.1-001A72?logo=react&logoColor=white)](https://docs.swmansion.com/react-native-reanimated/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Contributions](https://img.shields.io/badge/Contributions-Welcome-brightgreen)](CONTRIBUTING.md)

</div>

---

## ğŸ“± Demo

<div align="center">

**[ğŸ¥ Click Here to Watch Full Video Demo](https://www.dropbox.com/scl/fi/wylnfdej17svr0hjzjcdp/Theramind_v1.MP4?rlkey=35grs9eyzro4p7jzc1u4qw72a&st=y392fmwq&dl=0)**

<a href="https://www.dropbox.com/scl/fi/wylnfdej17svr0hjzjcdp/Theramind_v1.MP4?rlkey=35grs9eyzro4p7jzc1u4qw72a&st=y392fmwq&dl=0">
  <img src="https://img.shields.io/badge/â–¶ï¸_WATCH_DEMO-Theramind_v1.0-blueviolet?style=for-the-badge" alt="Watch Demo"/>
</a>

*Experience Theramind in action: Beautiful UI, smooth animations, and seamless conversations*

> ğŸ’¡ **Note**: Click the button above to watch the full demo video on Dropbox

</div>

---

## âœ¨ Features

### ğŸ¨ **Beautiful UI/UX**
- Modern gradient backgrounds with smooth animations
- Glass morphism effects for message bubbles
- 60fps animations powered by React Native Reanimated
- Haptic feedback for enhanced user interactions
- Dark mode optimized interface
- Smooth typing indicators and transitions

### ğŸ¤– **On-Device AI Processing**
- **Local LLM inference** using Gemma 3 1B or Llama 3.2 1B
- Fast token generation (15-30 tokens/sec on modern devices)
- 4-bit quantization for memory efficiency
- Runs completely offline - no internet required
- Context-aware conversations with memory
- Therapy-focused, empathetic AI personality

### ğŸ”’ **Privacy & Security**
- **100% on-device processing** - your data never leaves your phone
- No cloud services or data collection
- All conversations stored locally
- No API keys or external dependencies
- GDPR compliant by design
- Complete offline functionality

### ğŸ’¾ **Smart Data Management**
- Persistent conversation history
- Auto-save functionality
- Multiple conversation threads
- Conversation switching and management
- Delete individual conversations
- Local storage with AsyncStorage

### âš¡ **Performance Optimized**
- Efficient 4-bit GGUF model quantization
- Memory usage: ~1-2GB (including model)
- Smooth 60fps UI animations
- Optimized for modern smartphones (6GB+ RAM)
- Fast app startup and response times

---

## ğŸ› ï¸ Tech Stack

<table>
<tr>
<td valign="top" width="50%">

### Frontend
- **React Native** `0.81.5` - Cross-platform mobile framework
- **Expo** `~54.0.0` - Development platform
- **TypeScript** `5.3.3` - Type-safe JavaScript
- **Expo Router** `~6.0.14` - File-based routing
- **React Native Reanimated** `~4.1.1` - 60fps animations
- **React Native Gesture Handler** `~2.28.0` - Touch gestures

</td>
<td valign="top" width="50%">

### AI & Backend
- **llama.cpp** - Efficient LLM inference engine
- **react-native-llama** - React Native bindings
- **GGUF Models** - Quantized model format
- **Zustand** `4.5.0` - State management
- **AsyncStorage** `2.2.0` - Local persistence
- **Expo Haptics** - Tactile feedback

</td>
</tr>
</table>

---

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** `20.19.0+` (required for Expo SDK 54)
- **npm** or **yarn**
- **Expo Go** app on your mobile device
- **6GB+ RAM** on your phone (recommended for optimal performance)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Jkanishkha0305/Theramind.git
cd Theramind
```

2. **Install dependencies**
```bash
npm install
```

3. **Start the development server**
```bash
npm start
```

4. **Run on your device**
- Scan the QR code with **Expo Go** (iOS/Android)
- Or press `i` for iOS simulator / `a` for Android emulator

---

## ğŸ¤– Model Setup

Theramind requires a quantized GGUF model file for on-device AI inference.

### Recommended Models

#### Option 1: Gemma 3 1B (Recommended)
- **Size**: ~500MB (4-bit quantized)
- **Performance**: 15-30 tokens/sec
- **Download**: [Gemma 3 1B GGUF on Hugging Face](https://huggingface.co/models?search=gemma-3-1b-gguf)

#### Option 2: Llama 3.2 1B
- **Size**: ~500MB (4-bit quantized)
- **Performance**: 20-35 tokens/sec
- **Download**: [Llama 3.2 1B GGUF on Hugging Face](https://huggingface.co/models?search=llama-3.2-1b-gguf)

### Setup Steps

1. **Download your chosen model** from Hugging Face
2. **Place the model file** in `assets/models/` directory
   ```bash
   mkdir -p assets/models
   # Move your downloaded .gguf file here
   ```
3. **Update model path** in `src/services/LLMService.ts`:
   ```typescript
   const modelPath = 'assets/models/your-model-name.gguf';
   ```

### First Launch

The app will:
1. Check for a local model
2. Prompt you to download if not found
3. Initialize the model (may take 10-30 seconds)
4. Ready to chat!

---

## ğŸ“ Project Structure

```
Theramind/
â”œâ”€â”€ app/                          # Expo Router screens
â”‚   â”œâ”€â”€ _layout.tsx              # Root layout with navigation
â”‚   â”œâ”€â”€ index.tsx                # Splash/landing screen
â”‚   â”œâ”€â”€ onboarding.tsx           # Onboarding flow
â”‚   â””â”€â”€ chat.tsx                 # Main chat interface
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/              # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ GradientBackground.tsx   # Animated gradient
â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx        # Chat message bubbles
â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx            # Input component
â”‚   â”‚   â”œâ”€â”€ ConversationList.tsx     # Sidebar conversation list
â”‚   â”‚   â””â”€â”€ TypingIndicator.tsx      # Loading animation
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # Business logic & AI
â”‚   â”‚   â”œâ”€â”€ LLMService.ts            # Local LLM integration
â”‚   â”‚   â””â”€â”€ StorageService.ts        # Local data persistence
â”‚   â”‚
â”‚   â”œâ”€â”€ store/                   # State management
â”‚   â”‚   â””â”€â”€ chatStore.ts             # Zustand store
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # Utilities
â”‚   â”‚   â”œâ”€â”€ theme.ts                 # Design tokens
â”‚   â”‚   â””â”€â”€ animations.ts            # Reanimated configs
â”‚   â”‚
â”‚   â””â”€â”€ types/                   # TypeScript definitions
â”‚       â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ assets/                      # Static resources
â”‚   â””â”€â”€ models/                  # Place your GGUF models here
â”‚
â””â”€â”€ package.json                # Dependencies

```

---

## ğŸ¯ Development Status

### âœ… Completed Features
- [x] Beautiful gradient UI with 60fps animations
- [x] Glass morphism message bubbles
- [x] Smooth typing indicators
- [x] Multiple conversation threads
- [x] Conversation history management
- [x] Local storage with AsyncStorage
- [x] Haptic feedback
- [x] Onboarding flow
- [x] Navigation structure
- [x] State management with Zustand

### ğŸš§ In Progress
- [ ] LLM integration (react-native-llama)
- [ ] Model download UI
- [ ] Streaming token display
- [ ] Context window management

### ğŸ“‹ Planned Features
- [ ] Voice input/output (future)
- [ ] Conversation export/import
- [ ] Advanced model settings
- [ ] Custom AI personalities
- [ ] Mood tracking integration
- [ ] Journaling features

---

## âš¡ Performance

- **Animations**: 60fps with Reanimated
- **Inference Speed**: 15-30 tokens/sec (device dependent)
- **Model Load Time**: 10-30 seconds (first time)
- **Memory Usage**: ~1-2GB (including model)
- **Supported Devices**: iPhone 12+ / Android with 6GB+ RAM
- **Offline**: Works completely without internet

---

## ğŸ”§ Configuration

### Model Parameters

Customize AI behavior in `src/services/LLMService.ts`:

```typescript
const config = {
  temperature: 0.7,      // Creativity (0.0-2.0)
  maxTokens: 500,        // Response length
  topP: 0.9,             // Nucleus sampling
  topK: 40,              // Top-K sampling
  repeatPenalty: 1.1,    // Reduce repetition
};
```

### System Prompt

Modify the AI personality:

```typescript
const systemPrompt = `You are Theramind, a compassionate AI companion 
and mental wellness assistant. Be warm, empathetic, and non-judgmental.`;
```

---

## ğŸ› Troubleshooting

### Common Issues

**"Model not found" Error**
- Ensure model file is in `assets/models/` directory
- Check model path in `LLMService.ts`
- Verify model is a valid GGUF file

**Slow Inference Speed**
- Use 4-bit quantized models (not 8-bit or higher)
- Close background apps to free RAM
- Ensure device has 6GB+ RAM
- Try a smaller model (1B parameter)

**"Out of Memory" Error**
- Use 4-bit quantization
- Reduce context window size
- Close other apps
- Restart the app

**App Crashes on Launch**
- Clear app cache and restart
- Reinstall the app
- Check device RAM availability
- Verify model file integrity

**"Worklets Mismatch" Error**
```bash
# Clear all caches and restart
rm -rf .expo node_modules/.cache
npm install
npx expo start --clear
```

For more help, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md)

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

Please read our [Contributing Guidelines](CONTRIBUTING.md) for details.

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [llama.cpp](https://github.com/ggerganov/llama.cpp) for the amazing inference engine
- [Expo](https://expo.dev/) for the excellent development platform
- [React Native Reanimated](https://docs.swmansion.com/react-native-reanimated/) for smooth animations
- [Zustand](https://github.com/pmndrs/zustand) for simple state management
- All open-source LLM model creators (Gemma, Llama teams)
- The React Native community

---

## ğŸ“§ Support

- **Issues**: [GitHub Issues](https://github.com/Jkanishkha0305/Theramind/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Jkanishkha0305/Theramind/discussions)

---

## ğŸŒŸ Show Your Support

If you find this project helpful, please consider:
- â­ Starring the repository
- ğŸ› Reporting bugs
- ğŸ’¡ Suggesting new features
- ğŸ¤ Contributing code
- ğŸ“¢ Sharing with others

---

## ğŸ”’ Privacy Statement

Theramind is built with privacy as the core principle:
- **No data collection** - We don't collect any personal information
- **No tracking** - No analytics or usage tracking
- **No cloud services** - Everything runs on your device
- **No API calls** - Completely self-contained
- **Open source** - Inspect the code yourself

Your conversations are yours and yours alone.

---

<div align="center">

**Built with â¤ï¸ for mental wellness and privacy**

Made by [Kanishkha](https://github.com/Jkanishkha0305)

*Empowering personal wellness through privacy-first AI*

</div>
